#!/usr/bin/env python3
"""
ShapeLLM-Omni æ‹–è½¦é’©æ•°æ®é¢„å¤„ç†è„šæœ¬
å®Œæˆä»OBJæ–‡ä»¶åˆ°è®­ç»ƒæ•°æ®çš„å®Œæ•´æµç¨‹
"""

import os
import sys
import json
import hashlib
import random
import argparse
import pandas as pd
import numpy as np
import torch
import trimesh
import open3d as o3d
from pathlib import Path
from tqdm import tqdm
import tempfile

# æ·»åŠ ShapeLLM-Omniè·¯å¾„
sys.path.append('ShapeLLM-Omni')
from trellis.models.sparse_structure_vqvae import VQVAE3D
from huggingface_hub import hf_hub_download

class TrailerHookPreprocessor:
    def __init__(self, mesh_dir="mesh_output", output_dir="processed_data", use_cache=True):
        self.mesh_dir = Path(mesh_dir)
        self.output_dir = Path(output_dir)
        self.use_cache = use_cache
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # æ‹–è½¦é’©è®¾è®¡å˜ä½“æ˜ å°„
        self.hook_variants = {
            "Hook1.obj": "original design",
            "Hook2.obj": "widened and thickened support arm", 
            "Hook3.obj": "reduced base plate size",
            "Hook4.obj": "extended base plate length",
            "Hook5.obj": "lengthened support arm neck",
            "Hook6.obj": "thickened base plate",
            "Hook7.obj": "increased support arm height"
        }
        
        # 3Dç¼–è¾‘ä»»åŠ¡æ¨¡æ¿ (å®Œå…¨æŒ‰ç…§templates.txt)
        self.edit_templates = [
            "extended base plate for enhanced stability",
            "increased support arm height for better clearance",
            "lengthened support arm neck for improved reach",
            "reduced base plate size for space-saving installation",
            "thickened base plate for structural strength",
            "widened support arm for enhanced load capacity"
        ]
        
        # åŠ è½½ä»»åŠ¡æ¨¡æ¿
        self.load_templates()
        
        # åˆå§‹åŒ–3D VQ-VAE
        self.init_vqvae()
        
    def load_templates(self):
        """åŠ è½½ä»»åŠ¡æ¨¡æ¿ - å®Œå…¨æŒ‰ç…§templates.txt"""
        # Text-to-3Dæ¨¡æ¿ (å®Œæ•´åˆ—è¡¨)
        self.text_to_3d_templates = [
            "Create a 3D mesh using the following description:",
            "Create a 3D object using the following description:",
            "Create a 3D assets using the following description:",
            "Create a 3D content using the following description:",
            "Please generate a 3D mesh based on the prompt I provided:",
            "Please generate a 3D object based on the prompt I provided:",
            "Please generate a 3D assets based on the prompt I provided:",
            "Please generate a 3D content based on the prompt I provided:",
            "Create a 3D mesh of",
            "Create a 3D object of",
            "Create a 3D assets of",
            "Create a 3D content of",
            "generate a 3D mesh of",
            "generate a 3D model of",
            "generate a 3D object of",
            "generate a 3D assets of",
            "generate a 3D content of",
            "Please create a 3D mesh using the following details:",
            "Please create a 3D object using the following details:",
            "Please create a 3D assets using the following details:",
            "Please create a 3D content using the following details:",
            "Please generate a 3D mesh based on the description I provided:",
            "Please generate a 3D object based on the description I provided:",
            "Please generate a 3D assets based on the description I provided:",
            "Please generate a 3D content based on the description I provided:"
        ]

        # 3D Captionæ¨¡æ¿ (å®Œæ•´åˆ—è¡¨)
        self.caption_templates = [
            'Can you give a brief overview of this 3D voxel?',
            'Give a quick overview of the object represented by this 3D mesh.',
            'How would you describe the 3D form shown in this 3D voxel?',
            'What kind of structure does this 3D obj depict?',
            'What can you infer about the object from this 3D voxel?',
            'Convey a summary of the 3D structure represented in this 3D assets.',
            'Give a concise interpretation of the 3D data presented here.',
            'Express in brief, what this 3D mesh is representing.',
            'Explain the object this 3D content depicts succinctly.',
            'Describe the object that this 3D voxel forms.',
            'What is the nature of the object this 3D mesh is representing?',
            'Summarize the 3D object briefly.',
            'Offer a summary of the 3D object illustrated by this voxel.',
            'Can you briefly outline the shape represented by these mesh?',
            'Provide a short explanation of this 3D structure.',
            'Characterize the object this 3D content is illustrating.',
            'How would you summarize this 3D data?',
            "Provide an outline of this 3D shape's characteristics.",
            "Present a compact account of this 3D object's key features.",
            'What object is this voxel rendering?',
            'What does this collection of mesh represent?',
            'What kind of object is depicted by this mesh?',
            'Deliver a quick description of the object represented here.',
            'Offer a succinct summary of this 3D object.',
            'Offer a clear and concise description of this 3D mesh object.',
            'Share a brief interpretation of this 3D assets.',
            'Could you delineate the form indicated by this mesh?',
            'What kind of object is illustrated by this collection of voxel?',
            'How would you interpret this 3D object?'
        ]

    def find_cached_model(self, repo_id, filename):
        """æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹æ–‡ä»¶"""
        cache_base = ".cache/huggingface/hub"
        model_dir = f"models--{repo_id.replace('/', '--')}"
        snapshots_dir = os.path.join(cache_base, model_dir, "snapshots")

        if os.path.exists(snapshots_dir):
            # æŸ¥æ‰¾æœ€æ–°çš„å¿«ç…§ç›®å½•
            snapshots = [d for d in os.listdir(snapshots_dir) if os.path.isdir(os.path.join(snapshots_dir, d))]
            if snapshots:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„å¿«ç…§ï¼ˆé€šå¸¸åªæœ‰ä¸€ä¸ªï¼‰
                snapshot_dir = os.path.join(snapshots_dir, snapshots[0])
                model_path = os.path.join(snapshot_dir, filename)
                if os.path.exists(model_path):
                    return model_path
        return None

    def init_vqvae(self):
        """åˆå§‹åŒ–3D VQ-VAEæ¨¡å‹"""
        print("Loading 3D VQ-VAE model...")
        self.vqvae = VQVAE3D(num_embeddings=8192)
        self.vqvae.eval()

        # æ ¹æ®è®¾ç½®å†³å®šæ˜¯å¦ä½¿ç”¨ç¼“å­˜
        if self.use_cache:
            cached_path = self.find_cached_model("yejunliang23/3DVQVAE", "3DVQVAE.bin")
            if cached_path:
                print(f"âœ“ Using cached model weights: {cached_path}")
                filepath = cached_path
            else:
                print("âš  Cache not found, downloading from HuggingFace...")
                filepath = hf_hub_download(repo_id="yejunliang23/3DVQVAE", filename="3DVQVAE.bin")
        else:
            print("âš  Cache disabled, downloading from HuggingFace...")
            filepath = hf_hub_download(repo_id="yejunliang23/3DVQVAE", filename="3DVQVAE.bin")

        state_dict = torch.load(filepath, map_location="cpu")
        self.vqvae.load_state_dict(state_dict)
        self.vqvae = self.vqvae.to(self.device)
        print("âœ“ 3D VQ-VAE model loaded successfully")

    def get_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶SHA256å“ˆå¸Œ"""
        sha256 = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256.update(byte_block)
        return sha256.hexdigest()

    def convert_trimesh_to_open3d(self, trimesh_mesh):
        """è½¬æ¢trimeshåˆ°open3dæ ¼å¼"""
        o3d_mesh = o3d.geometry.TriangleMesh()
        o3d_mesh.vertices = o3d.utility.Vector3dVector(
            np.asarray(trimesh_mesh.vertices, dtype=np.float64)
        )
        o3d_mesh.triangles = o3d.utility.Vector3iVector(
            np.asarray(trimesh_mesh.faces, dtype=np.int32)
        )
        return o3d_mesh

    def rotate_points(self, points, axis='x', angle_deg=90):
        """æ—‹è½¬ç‚¹äº‘"""
        angle_rad = np.deg2rad(angle_deg)
        if axis == 'x':
            R = trimesh.transformations.rotation_matrix(angle_rad, [1, 0, 0])[:3, :3]
        elif axis == 'y':
            R = trimesh.transformations.rotation_matrix(angle_rad, [0, 1, 0])[:3, :3]
        elif axis == 'z':
            R = trimesh.transformations.rotation_matrix(angle_rad, [0, 0, 1])[:3, :3]
        else:
            raise ValueError("axis must be 'x', 'y', or 'z'")
        return points @ R.T

    def voxelize_mesh(self, obj_path):
        """ä½“ç´ åŒ–3Dç½‘æ ¼"""
        print(f"Voxelizing {obj_path}...")
        
        # åŠ è½½ç½‘æ ¼
        mesh = trimesh.load(obj_path, force='mesh')
        mesh = self.convert_trimesh_to_open3d(mesh)
        
        # æ ‡å‡†åŒ–é¡¶ç‚¹åˆ°[-0.5, 0.5]èŒƒå›´
        vertices = np.asarray(mesh.vertices)
        min_vals = vertices.min(axis=0)
        max_vals = vertices.max(axis=0)
        vertices_normalized = (vertices - min_vals) / (max_vals - min_vals)
        vertices = vertices_normalized * 1.0 - 0.5
        vertices = np.clip(vertices, -0.5 + 1e-6, 0.5 - 1e-6)
        mesh.vertices = o3d.utility.Vector3dVector(vertices)
        
        # åˆ›å»ºä½“ç´ ç½‘æ ¼
        voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh_within_bounds(
            mesh, voxel_size=1/64, 
            min_bound=(-0.5, -0.5, -0.5), 
            max_bound=(0.5, 0.5, 0.5)
        )
        
        # æå–ä½“ç´ åæ ‡
        vertices = np.array([voxel.grid_index for voxel in voxel_grid.get_voxels()])
        assert np.all(vertices >= 0) and np.all(vertices < 64), "Some vertices are out of bounds"
        vertices = (vertices + 0.5) / 64 - 0.5
        voxel = self.rotate_points(vertices, axis='x', angle_deg=90)
        
        return voxel

    def encode_voxel_to_tokens(self, voxel_points):
        """å°†ä½“ç´ ç¼–ç ä¸ºtokenåºåˆ—"""
        # è½¬æ¢ä¸ºç¨€ç–å¼ é‡æ ¼å¼
        coords = ((torch.from_numpy(voxel_points) + 0.5) * 64).int().contiguous()
        ss = torch.zeros(1, 1, 64, 64, 64, dtype=torch.long)
        ss[:, :, coords[:, 0], coords[:, 1], coords[:, 2]] = 1
        
        # ä½¿ç”¨VQ-VAEç¼–ç 
        with torch.no_grad():
            encoding_indices = self.vqvae.Encode(ss.to(dtype=torch.float32).to(self.device))
            tokens = encoding_indices[0].cpu().numpy().tolist()
        
        return tokens

    def tokens_to_mesh_string(self, tokens):
        """å°†tokenè½¬æ¢ä¸ºmeshå­—ç¬¦ä¸²æ ¼å¼"""
        mesh_str = "<mesh-start>"
        for token in tokens:
            mesh_str += f"<mesh{token}>"
        mesh_str += "<mesh-end>"
        return mesh_str

    def process_single_hook(self, hook_file):
        """å¤„ç†å•ä¸ªæ‹–è½¦é’©æ–‡ä»¶"""
        obj_path = self.mesh_dir / hook_file
        if not obj_path.exists():
            print(f"Warning: {obj_path} not found, skipping...")
            return None
            
        # ä½“ç´ åŒ–
        voxel_points = self.voxelize_mesh(obj_path)
        
        # ç¼–ç ä¸ºtokens
        tokens = self.encode_voxel_to_tokens(voxel_points)
        mesh_string = self.tokens_to_mesh_string(tokens)
        
        # è·å–è®¾è®¡æè¿°
        description = self.hook_variants[hook_file]
        
        return {
            'file': hook_file,
            'description': description,
            'mesh_string': mesh_string,
            'voxel_count': len(voxel_points)
        }

    def generate_training_data(self, processed_hooks):
        """ç”Ÿæˆè®­ç»ƒæ•°æ®"""
        training_data = []
        
        print("Generating training data...")
        
        # 1. Text-to-3Dä»»åŠ¡ (6æ¨¡æ¿ Ã— 7å˜ä½“ = 42æ¡)
        # æ ¼å¼: <prompt> â†’ response: <mesh-start><mesh-xxxx>.....<mesh-end>
        for hook_data in processed_hooks:
            templates = random.sample(self.text_to_3d_templates, 6)
            for template in templates:
                if template.endswith(":"):
                    prompt = f"{template} a trailer hitch with {hook_data['description']}"
                else:
                    prompt = f"{template} a trailer hitch with {hook_data['description']}"

                training_data.append({
                    "conversations": [
                        {
                            "from": "human",
                            "value": prompt
                        },
                        {
                            "from": "gpt",
                            "value": hook_data['mesh_string']
                        }
                    ],
                    "task_type": "text_to_3d",
                    "hook_variant": hook_data['file']
                })
        
        # 2. 3D Captionä»»åŠ¡ (6æ¨¡æ¿ Ã— 7å˜ä½“ = 42æ¡)
        # æ ¼å¼: <mesh-start><mesh-xxxx>.....<mesh-end><prompt> â†’ response: <description>
        for hook_data in processed_hooks:
            templates = random.sample(self.caption_templates, 6)
            for template in templates:
                # æ­£ç¡®æ ¼å¼: mesh_string + prompt
                prompt_with_mesh = f"{hook_data['mesh_string']}{template}"
                response = f"This 3D mesh represents a trailer hitch with {hook_data['description']}."

                training_data.append({
                    "conversations": [
                        {
                            "from": "human",
                            "value": prompt_with_mesh
                        },
                        {
                            "from": "gpt",
                            "value": response
                        }
                    ],
                    "task_type": "3d_caption",
                    "hook_variant": hook_data['file']
                })
        
        # 3. 3D Editedä»»åŠ¡ (1åŸå§‹ Ã— 6ç¼–è¾‘ = 6æ¡)
        # æ ¼å¼: <mesh-start><mesh-xxxx>.....<mesh-end><prompt> â†’ response: <mesh-start><mesh-xxxx>.....<mesh-end>
        original_hook = next(h for h in processed_hooks if h['file'] == 'Hook1.obj')
        edited_hooks = [h for h in processed_hooks if h['file'] != 'Hook1.obj']

        for i, edited_hook in enumerate(edited_hooks):
            edit_instruction = self.edit_templates[i]
            # æ­£ç¡®æ ¼å¼: åŸå§‹mesh + ç¼–è¾‘æŒ‡ä»¤
            prompt_with_mesh = f"{original_hook['mesh_string']}{edit_instruction}"

            training_data.append({
                "conversations": [
                    {
                        "from": "human",
                        "value": prompt_with_mesh
                    },
                    {
                        "from": "gpt",
                        "value": edited_hook['mesh_string']
                    }
                ],
                "task_type": "3d_edited",
                "original_hook": "Hook1.obj",
                "edited_hook": edited_hook['file'],
                "edit_instruction": edit_instruction
            })
        
        return training_data

    def run(self):
        """è¿è¡Œå®Œæ•´çš„é¢„å¤„ç†æµç¨‹"""
        print("ğŸš€ Starting trailer hook data preprocessing...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # å¤„ç†æ‰€æœ‰æ‹–è½¦é’©æ–‡ä»¶
        processed_hooks = []
        for hook_file in self.hook_variants.keys():
            result = self.process_single_hook(hook_file)
            if result:
                processed_hooks.append(result)
        
        print(f"âœ“ Processed {len(processed_hooks)} hook variants")
        
        # ç”Ÿæˆè®­ç»ƒæ•°æ®
        training_data = self.generate_training_data(processed_hooks)
        
        # ä¿å­˜è®­ç»ƒæ•°æ®
        output_file = self.output_dir / "trailer_hook_training_data.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(training_data, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜å¤„ç†ç»Ÿè®¡
        stats = {
            "total_samples": len(training_data),
            "text_to_3d_samples": len([d for d in training_data if d['task_type'] == 'text_to_3d']),
            "caption_samples": len([d for d in training_data if d['task_type'] == '3d_caption']),
            "edited_samples": len([d for d in training_data if d['task_type'] == '3d_edited']),
            "hook_variants_processed": len(processed_hooks),
            "processed_hooks": [h['file'] for h in processed_hooks]
        }
        
        stats_file = self.output_dir / "preprocessing_stats.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Preprocessing completed!")
        print(f"ğŸ“Š Generated {stats['total_samples']} training samples")
        print(f"   - Text-to-3D: {stats['text_to_3d_samples']}")
        print(f"   - 3D Caption: {stats['caption_samples']}")
        print(f"   - 3D Edited: {stats['edited_samples']}")
        print(f"ğŸ’¾ Data saved to: {output_file}")
        print(f"ğŸ“ˆ Stats saved to: {stats_file}")

    def save_voxel_visualization(self, processed_hooks):
        """ä¿å­˜ä½“ç´ å¯è§†åŒ–æ–‡ä»¶"""
        voxel_dir = self.output_dir / "voxels"
        voxel_dir.mkdir(exist_ok=True)

        for hook_data in processed_hooks:
            # é‡æ–°ä½“ç´ åŒ–ä»¥è·å–ç‚¹äº‘æ•°æ®
            obj_path = self.mesh_dir / hook_data['file']
            voxel_points = self.voxelize_mesh(obj_path)

            # ä¿å­˜ä¸ºPLYæ ¼å¼
            ply_file = voxel_dir / f"{hook_data['file'].replace('.obj', '.ply')}"
            self.save_ply_from_array(voxel_points, ply_file)

    def save_ply_from_array(self, vertices, filename):
        """ä¿å­˜ç‚¹äº‘ä¸ºPLYæ ¼å¼"""
        header = [
            "ply",
            "format ascii 1.0",
            f"element vertex {vertices.shape[0]}",
            "property float x",
            "property float y",
            "property float z",
            "end_header"
        ]
        with open(filename, "w") as f:
            f.write("\n".join(header) + "\n")
            np.savetxt(f, vertices, fmt="%.6f")

    def validate_training_data(self, training_data):
        """éªŒè¯è®­ç»ƒæ•°æ®æ ¼å¼"""
        print("Validating training data format...")

        required_keys = ["conversations", "task_type"]
        for i, sample in enumerate(training_data):
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            for key in required_keys:
                if key not in sample:
                    raise ValueError(f"Sample {i} missing required key: {key}")

            # æ£€æŸ¥å¯¹è¯æ ¼å¼
            conversations = sample["conversations"]
            if len(conversations) != 2:
                raise ValueError(f"Sample {i} should have exactly 2 conversations")

            if conversations[0]["from"] != "human" or conversations[1]["from"] != "gpt":
                raise ValueError(f"Sample {i} has incorrect conversation format")

        print("âœ“ Training data format validation passed")

def main():
    parser = argparse.ArgumentParser(description="Trailer Hook Data Preprocessing")
    parser.add_argument("--mesh_dir", default="mesh_output", help="Directory containing OBJ files")
    parser.add_argument("--output_dir", default="processed_data", help="Output directory")
    parser.add_argument("--save_voxels", action="store_true", help="Save voxel PLY files")
    parser.add_argument("--validate", action="store_true", help="Validate training data format")
    parser.add_argument("--no_cache", action="store_true", help="Disable using cached model weights")

    args = parser.parse_args()

    try:
        preprocessor = TrailerHookPreprocessor(args.mesh_dir, args.output_dir, use_cache=not args.no_cache)

        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        missing_files = []
        for hook_file in preprocessor.hook_variants.keys():
            if not (Path(args.mesh_dir) / hook_file).exists():
                missing_files.append(hook_file)

        if missing_files:
            print(f"âŒ Missing hook files: {missing_files}")
            print(f"Please ensure all hook files are in {args.mesh_dir}/")
            return

        preprocessor.run()

        # å¯é€‰åŠŸèƒ½
        if args.save_voxels:
            print("Saving voxel visualizations...")
            # éœ€è¦é‡æ–°å¤„ç†ä»¥è·å–ä½“ç´ æ•°æ®
            processed_hooks = []
            for hook_file in preprocessor.hook_variants.keys():
                result = preprocessor.process_single_hook(hook_file)
                if result:
                    processed_hooks.append(result)
            preprocessor.save_voxel_visualization(processed_hooks)
            print("âœ“ Voxel PLY files saved")

        if args.validate:
            # åŠ è½½å¹¶éªŒè¯ç”Ÿæˆçš„è®­ç»ƒæ•°æ®
            output_file = Path(args.output_dir) / "trailer_hook_training_data.json"
            with open(output_file, 'r', encoding='utf-8') as f:
                training_data = json.load(f)
            preprocessor.validate_training_data(training_data)

    except Exception as e:
        print(f"âŒ Error during preprocessing: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
