# ShapeLLM-Omni æ‹–è½¦é’©è®¾è®¡LoRAå¾®è°ƒé¡¹ç›®

åŸºäºShapeLLM-Omniæ¨¡å‹ï¼Œä½¿ç”¨7ä¸ªæ‹–è½¦é’©è®¾è®¡å˜ä½“è¿›è¡ŒLoRAå¾®è°ƒï¼Œé‡‡ç”¨å¤šæ¨¡æ¿æ•°æ®å¢å¼ºç­–ç•¥ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

**å‚è€ƒè®ºæ–‡**: [ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding](https://arxiv.org/html/2506.01853v1)

**æ ¸å¿ƒåŠŸèƒ½**:
- 7ä¸ªæ‹–è½¦é’©è®¾è®¡å˜ä½“çš„3Dç”Ÿæˆå’Œç†è§£
- å¤šä»»åŠ¡è®­ç»ƒï¼šText-to-3Dã€3D-captionã€3D-edited
- LoRAå¾®è°ƒä¼˜åŒ–ï¼Œä¸“é—¨é’ˆå¯¹æ‹–è½¦é’©è®¾è®¡

**æ•°æ®è§„æ¨¡**: 90æ¡è®­ç»ƒæ ·æœ¬
- Text-to-3D: 42æ¡ (6æ¨¡æ¿ Ã— 7å˜ä½“)
- 3D-caption: 42æ¡ (6æ¨¡æ¿ Ã— 7å˜ä½“)
- 3D-edited: 6æ¡ (1åŸå§‹ Ã— 6ç¼–è¾‘)

**æ‹–è½¦é’©è®¾è®¡å˜ä½“**:
- Hook1: åŸå§‹è®¾è®¡
- Hook2: åŠ å®½åŠ åšæ”¯æ’‘è‡‚
- Hook3: ç¼©å°åº•æ¿
- Hook4: å»¶é•¿åº•æ¿é•¿åº¦
- Hook5: å»¶é•¿æ”¯æ’‘è‡‚é¢ˆéƒ¨
- Hook6: åŠ åšåº•æ¿
- Hook7: å¢åŠ æ”¯æ’‘è‡‚é«˜åº¦


## ï¿½ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚
- Python 3.10+
- CUDA 11.8+ (æ¨è)
- 16GB+ RAM
- 8GB+ GPUå†…å­˜

### å®‰è£…ä¾èµ–
```bash
# å®‰è£…ShapeLLM-Omniä¾èµ–
cd ShapeLLM-Omni
pip install -r requirements.txt

# è¿”å›é¡¹ç›®æ ¹ç›®å½•
cd ..
```

### ç¯å¢ƒæ£€æŸ¥
```bash
# æ£€æŸ¥CUDAå¯ç”¨æ€§
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# æ£€æŸ¥GPUå†…å­˜
nvidia-smi
```

## ğŸ“Š æ•°æ®å¤„ç†æµç¨‹

### æ­¥éª¤1: å‡†å¤‡æ•°æ®
å°†BDFæ–‡ä»¶æ”¾å…¥`bdf_data/`ç›®å½•ï¼ŒæŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡ï¼š
```
bdf_data/
â”œâ”€â”€ orginal/                    # åŸå§‹è®¾è®¡
â”œâ”€â”€ Extend the base plate lengthwise/
â”œâ”€â”€ Increase the overall height of the support arm/
â”œâ”€â”€ Lengthen the neck of the support arm/
â”œâ”€â”€ Shrink the base plate/
â”œâ”€â”€ Thicken the base plate/
â””â”€â”€ Widen and thicken the support arm/
```

### æ­¥éª¤2: BDFåˆ°Meshè½¬æ¢
```bash
python bdf_to_mesh_preprocessor.py --input_dir bdf_data --output_dir mesh_output
```

### æ­¥éª¤3: ç”Ÿæˆè®­ç»ƒæ•°æ®
```bash
python preprocess_trailer_hooks.py --mesh_dir mesh_output --output_dir processed_data
```
## ğŸ”§ æ•°æ®é¢„å¤„ç†è¯¦è§£

### é¢„å¤„ç†è„šæœ¬åŠŸèƒ½
`preprocess_trailer_hooks.py`æä¾›å®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµæ°´çº¿ï¼š

**æ ¸å¿ƒåŠŸèƒ½**:
- ä½“ç´ åŒ–ï¼šå°†OBJæ–‡ä»¶è½¬æ¢ä¸º64Â³ä½“ç´ è¡¨ç¤º
- VQ-VAEç¼–ç ï¼šä½¿ç”¨é¢„è®­ç»ƒ3D VQ-VAEå°†ä½“ç´ ç¼–ç ä¸ºtokenåºåˆ—
- å¤šä»»åŠ¡æ•°æ®ç”Ÿæˆï¼šè‡ªåŠ¨ç”Ÿæˆä¸‰ç§ä»»åŠ¡çš„è®­ç»ƒæ ·æœ¬
- æ¨¡æ¿éšæœºåŒ–ï¼šæ¯ä¸ªæ ·æœ¬ä½¿ç”¨éšæœºé€‰æ‹©çš„æç¤ºæ¨¡æ¿

**ä½¿ç”¨æ–¹æ³•**:
```bash
# åŸºæœ¬ä½¿ç”¨
python preprocess_trailer_hooks.py

# å®Œæ•´åŠŸèƒ½
python preprocess_trailer_hooks.py \
    --mesh_dir mesh_output \
    --output_dir processed_data \
    --save_voxels \
    --validate
```

**è¾“å‡ºæ–‡ä»¶**:
- `trailer_hook_training_data.json` - 90æ¡è®­ç»ƒæ ·æœ¬
- `preprocessing_stats.json` - å¤„ç†ç»Ÿè®¡ä¿¡æ¯
- `voxels/*.ply` - ä½“ç´ å¯è§†åŒ–æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰

### ä»»åŠ¡æ ¼å¼è¯´æ˜

**Text-to-3D**: `<prompt>` â†’ `<mesh-start><mesh-tokens><mesh-end>`
```json
{
  "conversations": [
    {"from": "human", "value": "Create a 3D mesh of a trailer hitch with original design"},
    {"from": "gpt", "value": "<mesh-start><mesh0><mesh1>...<mesh-end>"}
  ]
}
```

**3D-caption**: `<mesh-tokens><prompt>` â†’ `<description>`
```json
{
  "conversations": [
    {"from": "human", "value": "<mesh-start>...<mesh-end>Give a quick overview of this 3D mesh."},
    {"from": "gpt", "value": "This 3D mesh represents a trailer hitch with original design."}
  ]
}
```

**3D-edited**: `<original-mesh><edit-instruction>` â†’ `<edited-mesh>`
```json
{
  "conversations": [
    {"from": "human", "value": "<mesh-start>...<mesh-end>extended base plate for enhanced stability"},
    {"from": "gpt", "value": "<mesh-start><edited-tokens><mesh-end>"}
  ]
}
```

## ğŸ¯ LoRAå¾®è°ƒ

### å¾®è°ƒè„šæœ¬
```bash
python lora_finetune_shapellm.py --data_file processed_data/trailer_hook_training_data.json
```

### é…ç½®æ–‡ä»¶
è®­ç»ƒå‚æ•°åœ¨`llamafactory_configs/train_shapellm_lora.yaml`ä¸­é…ç½®ã€‚

### è¾“å‡º
å¾®è°ƒåçš„LoRAé€‚é…å™¨ä¿å­˜åœ¨`lora_output/`ç›®å½•ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
ShapeLLM-Trailer-Hook-LoRA/
â”œâ”€â”€ README.md                           # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ preprocess_trailer_hooks.py         # ä¸»é¢„å¤„ç†è„šæœ¬
â”œâ”€â”€ bdf_to_mesh_preprocessor.py         # BDFè½¬æ¢è„šæœ¬
â”œâ”€â”€ lora_finetune_shapellm.py          # LoRAå¾®è°ƒè„šæœ¬
â”œâ”€â”€ llamafactory_configs/               # è®­ç»ƒé…ç½®
â”‚   â””â”€â”€ train_shapellm_lora.yaml
â”œâ”€â”€ ShapeLLM-Omni/                     # åŸå§‹ShapeLLMé¡¹ç›®
â”œâ”€â”€ bdf_data/                          # BDFæ•°æ®ç›®å½•ï¼ˆç©ºï¼‰
â”œâ”€â”€ mesh_output/                       # Hook OBJæ–‡ä»¶ç›®å½•ï¼ˆç©ºï¼‰
â”œâ”€â”€ processed_data/                    # é¢„å¤„ç†è¾“å‡ºç›®å½•ï¼ˆç©ºï¼‰
â”œâ”€â”€ training_data/                     # è®­ç»ƒæ•°æ®ç›®å½•ï¼ˆç©ºï¼‰
â”œâ”€â”€ lora_output/                       # LoRAè¾“å‡ºç›®å½•ï¼ˆç©ºï¼‰
â””â”€â”€ data/                             # é€šç”¨æ•°æ®ç›®å½•ï¼ˆç©ºï¼‰
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### ç³»ç»Ÿè¦æ±‚
- **GPUå†…å­˜**: å»ºè®®8GB+ç”¨äºVQ-VAEæ¨ç†
- **ç³»ç»Ÿå†…å­˜**: å»ºè®®16GB+ç”¨äºç½‘æ ¼å¤„ç†
- **å­˜å‚¨ç©ºé—´**: çº¦100MBç”¨äºè¾“å‡ºæ–‡ä»¶

### ç¼“å­˜ä¼˜åŒ–
è„šæœ¬ä¼šè‡ªåŠ¨ä½¿ç”¨HuggingFaceç¼“å­˜çš„æ¨¡å‹æƒé‡ï¼Œé¿å…é‡å¤ä¸‹è½½ï¼š
```bash
# å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼ˆå¦‚æœéœ€è¦ï¼‰
python preprocess_trailer_hooks.py --no_cache
```

### å¸¸è§é—®é¢˜
1. **CUDAå†…å­˜ä¸è¶³**: ä½¿ç”¨`export CUDA_VISIBLE_DEVICES=""`å¼ºåˆ¶ä½¿ç”¨CPU
2. **OBJæ–‡ä»¶åŠ è½½å¤±è´¥**: æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œè·¯å¾„
3. **ä½“ç´ åŒ–ç»“æœä¸ºç©º**: ç¡®è®¤ç½‘æ ¼æ˜¯å°é—­çš„ä¸”å¤§å°åˆé€‚

## ğŸ“š å‚è€ƒèµ„æ–™

- [ShapeLLM-Omniè®ºæ–‡](https://arxiv.org/html/2506.01853v1)
- [TRELLISé¡¹ç›®](https://github.com/microsoft/TRELLIS)
- [Qwen2.5-VL](https://github.com/QwenLM/Qwen2.5-VL)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚

